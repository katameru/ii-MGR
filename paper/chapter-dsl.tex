\chapter{DSL}

\section{Dive into DSLs}

Domain specific languages (DSLs) are computer languages that are designed to express solutions to problems from a specific domain. It's not easy to formulate a strict definition of what is and isn't a DSL. It can be useful to define DSLs in opposition to general purpose languages (GPLs). DSLs are most expressive when they are used to solve programs in their own domain, whereas GPLs are the same across many domains. Even then classifying some languages is problematic. Let us consider a spectrum of languages: Bash, PostScript, TeX, CSS, regular expressions, or message filters in email software. Bash is specialized for creating shell scripts, but is still a fully fledged language on its own. On the other hand we could argue that message filters are barely a language at all.

DSLs are a powerful element of a developers toolbox, allowing us to write programs that are simpler and much more expressive. One one hand they provide abstractions of concepts that are part of the domain by making them structural elements of the language. On the other hand they can abstract from the details of computation part of the solution. However, this means that to create a good DSL we must both: have a very good understanding of the domain, so that we can not only model solutions but also a general framework for solutions, and be a good developer so that the abstractions we provide are well designed.

The general idea of DSLs is to trade-off the ease (or even ability) to solve general problems for the value we can add to solving problems from a specific domain. Some examples of added value can be:
\begin{itemize}
	\item syntax and semantics that is easy to learn by non-programmers and resembles notation used by domain experts
	\item syntax that includes idioms common in the domain to make code more expressive
	\item programs can be analyzed and verified so that some errors are caught early
	\item program execution can be optimized using domain knowledge
\end{itemize}

For example, SQL is the DSL of relational databases. Its is designed to express the logic of data manipulation and querying in a relational database, and its notation uses the mathematical model of relational algebras. Most database engines contain query optimizers which use both data available at query definition and at runtime to help performance. On the other hand, some computations can be very hard to express, and some dialects aren't even Turing complete.

There are many ways to classify DSLs \autocite{Gunther:2011} based on their properties. We can study their appearance, origin (relation to implementing language), originality, how it's implemented or what is its purpose. In this paper we focus mainly Scala, and how it enables DSL creation. Since the features that are said to make Scala a good language for DSLs relate to building internal DSL, we will highlight and analyze the patterns relating to building abstractions and notations.

\section{Classification}
One way to classify DSLs is to look at their relationship with the language used to implement them \autocite{Artho:2015, Gunther:2011}. The basic split is between external and internal (or embedded) DSLs. An external DSL is one that has syntax wholly independent from the implementing language and is a language by its own right. An embedded DSL is essentially a library of the implementing (or host) language which provides abstractions over the domain-specific knowledge.

\subsection{External DSLs}

External DSLs gives us the most flexibility of syntax. Since we are not constrained by the rules of the host language, the source code can be have a form that is the best way of modeling a solution of a domain problem: a set of symbolic equations, files in a specific hierarchy on disk or a list of turtle movement instructions. Custom syntax usually means a significant rise in implementation complexity and a drop in usability. 

\subsubsection{Parsing custom syntax}

An important issue in implementing external DSLs is that we need to parse the source files into an internal representation. Scala has several options for parsing libraries and parser generators which simplify this step significantly. However, languages with complex (or poorly designed) grammars will still result in complex parsers, and any input that isn't text-based (e. g. image, binary file) will need to be parsed using custom-written code.

\subsubsection{End-user independence}

The source code of programs written in external DSLs is completely separate from the implementation. To the end-user, this means that they don't need to have access to the implementation source code and build pipeline to write programs in the DSL. This allows use to, for example, embed a DSL in a commercial application. Customers can then extend the functionality of the program without having access to confidential implementation data.

\subsubsection{Developer tools}

A usability issue that arises when we use an external DSL is that there are no development tools that can help the programmer. Unless we implement it ourselves, we have no syntax highlighting or auto-completion in an editor. We also lose the ability to easily debug code. If we compile the code into an executable we must manually add debug symbols. If we use an interpreter written in the host language, we must keep information about the piece of source code we are currently running, which sometimes can be impossible.

\subsection{Internal DSL}

An internal DSL leverages the the host language to build programs. This solution can be severely limiting in terms of syntax because the DSL grammar needs to conform to the grammar of the host language. However, some languages (Scala included) have ways to adapt their syntax into multiple forms.

A large benefit of using internal DSLs is that we don't need to worry about parsing. We can also use the type system of the host language to embed a type system in the DSL.

%This isn't great
A nice property of internal DSLs is that they can inter-operate with other programs written in the host language. For example, we can have an internal DSL in Scala that allows us to run computations on large remote datasets. We can then lift functions from a third-party Scala library into our DSL to run complex computations on our data.

Internal DSLs can be further split into two groups: shallow and deep embeddings.

\subsubsection{Shallow embeddings}

A shallow embedding structures and names constructs in the host language in such a way that makes a program written in the DSL map directly onto a program in the host language with the same semantics.

In this situation every stage of a programs lifetime, from parsing to execution is handled by the host language. This gives us all the benefits that we would have when writing a program in the host language: development tools, an optimizing compiler/interpreter, and externally verified code generation.

%reference
\begin{lstlisting}[caption=Example ScalaTest code, label=code:scalatest_sample]
  "A Stack" should "pop values in last-in-first-out order" in {
    val stack = new Stack[Int]
    stack.push(1)
    stack.push(2)
    stack.pop() should be (2)
    stack.pop() should be (1)
  }
  it should "throw NoSuchElementException if an empty stack is popped" in {
    val emptyStack = new Stack[Int]
    a [NoSuchElementException] should be thrownBy {
      emptyStack.pop()
    } 
  }
\end{lstlisting}

On Listing \ref{code:scalatest_sample} we have a ScalaTest test scenario. We can see that normal Scala code is interspersed with ScalaTest code.
The lines
\begin{verbatim}
"A Stack" should "pop values in last-in-first-out order" in {
it should "throw NoSuchElementException if an empty stack is popped" in {
\end{verbatim}
define test case names, and the lines
\begin{verbatim}
stack.pop() should be (2)
stack.pop() should be (1)
a [NoSuchElementException] should be thrownBy { emptyStack.pop() }
\end{verbatim}
define assertions about code behavior. When executed, the Scala code is run and the assertions are checked. We then receive a descriptive report about which tests failed and which succeeded.


\subsubsection{Deep embeddings}

A deep embedding separates the representation of the DSL from its execution. We use the host language to create the structure of a program, which will be later compiled or interpreted by another part of the DSL.

\begin{lstlisting}[caption=Sample spark code, label=code:spark_sample]
val rdd = sparkContext.
	fromFile("data.csv").
	filter(...).
	map(...)

println(rdd.sum)
\end{lstlisting}

Seen on \ref{code:spark_sample} is an abbreviated Apache Spark\textsuperscript{TM} program. The variable rdd holds metadata that describe the loading and transforming of some data. This will be compiled to an execution plan and executed on multiple computers, completely transparently to the user.

While this form of DSL doesn't make any allowances for handy syntax, it can be much more expressive and powerful than a shallow embedding. A shallow embedding needs to map cleanly into the host language. A deep embedding doesn't have that restriction, which opens up the possibility of using more powerful abstractions.

Furthermore, while a deep DSL requires the implementation of a custom compiler/interpreter, it gives us the option to embed domain knowledge into the execution of a program. With an interpreter, we can use information gathered at runtime to make optimizations that would not be possible with a naive interpreter. If we compile a program to native code, we can generate code that uses assumptions that would not be available to a generic compiler. We can also generate code for non-standard targets, such as GPUs or FPGAs.

\section{Common patterns}

We describe the following notation patterns based on \autocite{Gunther:2011}:
\begin{itemize}
	\item Layout patterns - these patterns allow us to manipulate how the source code presents visually. Code layout can represent a hierarchy or other relationship between domain objects.
	\begin{enumerate}
		\item Block scope - arrange and group expressions in a way that represent their hierarchy in the domain. Code listing~\ref{code:scalatest_sample} shows us putting each separate test in it's own logical scope.
		\item Method chaining - make actions on domain objects be a result of sequentially applying methods. This way a composite action can be read fluently. Listing~\ref{code:scalatest_sample} uses this in making test and assertion definitions read like a sentence in English.
		\item Keyword arguments - allow arguments to methods be passed with explicit specification of the parameter name. This way the user doesn't need to know the implementation detail of the order of parameters in a function call.
	\end{enumerate}
	\item Expression patterns - these patterns allow us to separate ourselves from the host language by removing details of its operation.
	\begin{enumerate}
		\item Seamless constructor - keep the user from instantiating objects since things like memory management semantics shouldn't be a part of the DSL.
		\item Operator expressions - use custom implementations for operators like \texttt{+}, \texttt{-}, \texttt{*} where appropriate.
	\end{enumerate}
	\item Support patterns - these patterns allow us to further simplify our language
	\begin{enumerate}
		\item Clean methods calls - remove unnecessary symbols from method calls
		\item Custom return objects - instead of returning simple values from the host language, wrap results in a custom object. This can provide additional functionality and be reused in other parts of the DSL.
	\end{enumerate}
\end{itemize}

These patterns allow a DSL to better model the domain by folding more knowledge into the structure of the language. They also allow us to abstract away from the language by removing symbols and expressions that are not part of the DSL.
