\chapter{Scala features}
%reference
The core philosophy of scala is for it to be a 'scalable language', one which can adapt to the needs of its users. The creators wanted it to be an equally good choice for both small, simple programs and for large components of complex systems. To this end, Scala contains many different language features, some of which are explicitly in service of implementing DSLs. In this chapter we explore how the various patterns used in DSL implementation are supported in Scala.

\section{Parsing}

Scala has good support for creating parsers. There is a Scala standard parser combinator library \texttt{scala.util.parsing}, third-party parsing libraries like \texttt{FastParse}, and a parser generator utility \texttt{parboiled2} written in scala. Thanks to Java interop we can also use parsing libraries for Java. When writing custom parsers, aspects of the language like pattern matching and first-class functions are extremely helpful in keeping the code concise and readable. While this doesn't make the effort needed to create a parser for inconsequential, it does make Scala an attractive choice for implementing external DSLs.

\section{Execution}

While the interpretation of a program in AST form  (usually) doesn't pose much problem, it is much harder to generate an executable binary file. There exist Scala libraries that allow the generation of JVM classfiles such as \texttt{Cafebabe}, but I have not found a library that allows for the writing of any binary executable format. This is problematic if we want to execute programs written in the DSL in an environment that does not support the JVM.

\section{Internal modeling}

\subsection{Implicits}

The implicits mechanism in Scala has two main components: implicit values/parameters, and implicit conversions. Although these components have different uses and meaning, they usually serve a common goal: to hide away a detail of the implementation that is necessary, but doesn't have to be exposed to the user at all times.

\subsubsection{Implicit values/parameters}

A function can declare that some of its arguments are {\it implicit}. These arguments can be omitted at the call site, and the compiler will perform an {\it implicit lookup}. This action searches in a number of places for a value of the type declared in the argument list, and applies it if found. Implicit values can also be retrieved using the function \texttt{implicitly[T]}. An common use is in functions that want to separate arguments that are logically part of the computation from arguments that represent some execution context. For example, in a library that provides support for asynchronous computations we would have an \texttt{ExecutorService} that provides access to a configured thread pool. Functions from this library would require an \texttt{ExecutorService} as an argument to provide async functionality. Marking the \texttt{ExecutorService} as implicit allows us to omit it from the function calls and unclutter our code, as shown in listings \ref{code:without_implicit} and \ref{code:with_implicit}

\begin{lstlisting}[caption=Code without implicits, label=code:without_implicit]
def async[T](code: => T)(ex: ExecutorService) = ...
def scheduleOnce[T](code: => T, delay: Duration)(ex: ExecutorService) = ...

val ex: ExecutorService = ???
val k = async(expensiveOperation1())(ex)
val v = async(expensiveOperation2())(ex)
scheduleOnce(doThisAgain(), 1.hour)(ex)
\end{lstlisting}

\begin{lstlisting}[caption=Code with implicits, label=code:with_implicit, float]
def async[T](code: => T)(implicit ex: ExecutorService) = ...
def scheduleOnce[T](code: => T, delay: Duration)(implicit ex: ExecutorService) = ...

implicit val ex: ExecutorService = ...
val k = async(expensiveOperation1())
val v = async(expensiveOperation2())
scheduleOnce(doThisAgain(), 1.hour)
\end{lstlisting}

\subsubsection{Implicit conversions}
Unary functions can be marked as {\it implicit} to become implicit conversions. This allows us to use expressions of type \texttt{A} as if they had type \texttt{B}, as long as we have an implicit conversion of type \texttt{A => B} in scope. This includes method calls, so we can call methods of type \texttt{B} on values of type \texttt{A}. Implicit conversions can be useful when we are using a library that requires a datatype that is different from what is used internally. Listing \ref{code:conversions} shows an interface that uses byte arrays, but we use implicit conversions to transparently use String within our program.

\begin{lstlisting}[caption=Implicit conversions, label=code:conversions, float]
def put(key: Array[Byte], value: Array[Byte]) = ...
def get(key: Array[Byte]): Array[Byte] = ...

implicit def bytesToString(bytes: Array[Byte]): String = new String(bytes)
implicit def stringToBytes(string: String): Array[Byte]= string.getBytes

put("k1", "v1")
put("k2", "v2")
val result: String = get("k3")
\end{lstlisting}

\subsubsection{Implicit classes}
An implicit class is a shorthand definition of a class with a one-argument constructor alongside an implicit conversion from the argument to that class. This simplifies the implementation of the 'Enriched Class' pattern, which imitates adding methods to existing classes. Listing \ref{code:implicit_classes} shows a simple extension of the Int class. Now the methods \texttt{toHexString} is available on any instance of \texttt{Int} as long as the implicit class can be located.

%reference
\begin{lstlisting}[caption=Implicit class, label=code:implicit_classes, float]
implicit class RichInt(val self: Int) {
  def toHexString: String = java.lang.Integer.toHexString(self)
}

val i: Int = 5
println(i.toHexString)
\end{lstlisting}

\subsubsection{Context bounds}
Context bounds are a way to express more information at the type system level. The expressions \texttt{def f[T: Ordered](x: T) = \ldots} means that for a given type\texttt{T}, there exists an implementation of the trait \texttt{Ordered}, i. e. there exists a value of type Ordered[T]. This is actually just syntactic sugar which compiles to \texttt{def f[T](x: T)(implicit ev: Ordered[T])}. This mechanism is often used to emulate the behavior of Haskell type classes. Listing \ref{code:context_bounds} presents the implementation of the Show type class in Scala, which us slightly more verbose than in Haskell.

\begin{lstlisting}[caption=Context bounds, label=code:context_bounds, float]
trait Show[T] {
  def show(t: T): String
}
def print[T: Show](t: T) = {
  val str = implicitly[Show[T]].show(t)
  println(str)
}

implicit val showableInt: Show[Int] = new Show[Int] { def show(i: Int): String = i.toString }
implicit val showableFloat: Show[Float] = new Show[Float] { def show(f: Float): String = f.toString }
print(1)
print(2f)
print("3") //will not compile since there is no implementation od Show[String]
\end{lstlisting}

There is a similar construct called the view bound. The code \texttt{def f[T <\% B](x: T)} means that the type \texttt{T} can be viewed as as type \texttt{B}, and it desugars to \texttt{def f[T](x: T)(implicit ev: T => B)}. However, this is currently deprecated and will be removed in future versions of Scala, as it can be easil reproduce using context bounds.

\subsubsection{Implicit lookup}
%reference
\begin{enumerate}
	\item First look in current scope
	\begin{itemize}
		\item Implicits defined in current scope (\texttt{implicit val x = ...})
    \item Explicit imports (\texttt{import dsl.byte2String})
    \item wildcard imports (\texttt{import dsl.\_})
	\end{itemize}
	\item Now look at associated types in
	\begin{itemize}
		\item Companion objects of a type
		\item Implicit scope of an argumentâ€™s type
		\item Implicit scope of type arguments
		\item Outer objects for nested types
	\end{itemize}
\end{enumerate}

The implicits found in group 1 take precedence over implicits found in group 2. If multiple matching implicits are found, we choose the one with the most specific type. Otherwise, if none are found or we cannot disambiguate the implicit, the compilation fails.
        
\subsubsection{Criticisms}

Criticizing implicits is a common thread in online discussions about Scala. While not actually broken, implicits are a powerful and complex feature that is very prone to abuse.

The Scala collections library is an interesting example of implicit parameter (ab)use. Sometimes calles the "Longest suicide note in history" \autocite{lakes:2009}, it makes uses implicit parameters and the \texttt{CanBuildFrom} type class to provide robust operations on collections. Looking at the \texttt{map} method of \texttt{List[A]} which we expect to have the type signature \texttt{def map[B](f: A => B): List[B]}. The actual signature is \texttt{def map[B, That](f: A => B)(implicit bf: CanBuildFrom[Repr, B, That]): That}. Listing~\ref{code:bitset} (taken from a response to \autocite{lakes:2009}) shows that the implicit parameter in \texttt{map} is used to find the best possible return type for that method. While this is a powerful result, it presents less like functionality and more like a leaky abstraction. This is underlined by the fact that in newer versions of Scala the documentation doesn't show the real type, but the one that we expected in the beginning.

\begin{lstlisting}[caption=Bitset example, label=code:bitset]
scala> val bits = BitSet(1, 2, 3)
bits: scala.collection.immutable.BitSet = BitSet(1, 2, 3)

scala> val shifted = bits map { _ + 1 }
shifted: scala.collection.immutable.BitSet = BitSet(2, 3, 4)

scala> val displayed = bits map { _.toString + "!" }
displayed: scala.collection.immutable.Set[java.lang.String] = Set(1!, 2!, 3!)
\end{lstlisting}

Leaky abstractions expose the main problem of implicits, which is the large cognitive load to reason about them. When we encounter a problem or confusion with implicits, we cannot immediately say where a value came from. We need to know the implicit lookup algorithm which, while not complex, is not intuitive. Poorly designed implicit conversions can also hide errors. Every time there is a type error in a program, the implicit lookup algorithm tries to find a conversion which will let it compile. We now run a risk of accidentally compiling code that should have caused a type error because it just happened to find a fitting conversion.

\section{Method invocation}

Basic Scala method invocation is identical to Java method invocation. However, there are various alternatives to that notation that Scala allows.

\begin{itemize}
	\item When invoking methods that don't take arguments, we can omit the empty parentheses (\texttt{list.size} instead of \texttt{list.size()}).
	\item When invoking a methods that takes one parameter, we can use the infix notation, that is omit the dot and parentheses ((\texttt{list append 1} instead of \texttt{list.append(1)}))
	\item We can chain infix method invocations. \texttt{a m1 a1 m2 a2 m3} compiles as \texttt{a.m1(a1).m2(a2).m3()}
	\item If we keep parentheses around methods with multiple arguments, we can omit all dots in an expression. \texttt{a m1(a1, a2) m2 a2} will compile to \texttt{a.m1(a1, a2).m2(a2)}
\end{itemize}

These syntax options are crucial in enabling the Method Chaining and Clean Method Calls patterns. However care must be taken to understand the rules of how expressions like these are parsed. Code listings \ref{code:dotless1} and \ref{code:dotless2} show two expressions that look extremely similar. However, the expression in listing \ref{code:dotless1} compiles to \texttt{a.m(m).b}, whereas the other expression is actually two expressions: \texttt{a.m(); m.b()}. In a well designed language this would usually cause a compilation error, but some DSLs might want to reuse the same name in different contexts, which could lead to both code snippets being valid.


\begin{lstlisting}[caption=Parsing quirks, label=code:dotless1]
a m
m b
\end{lstlisting}

\begin{lstlisting}[caption=Parsing quirks, label=code:dotless2]
a m

m b
\end{lstlisting}

\section{Operator overloading}

Scala allows us to define methods whose names contain symbols. When combined with infix method invocation we get a notation that resembles operator overloading, but is in fact just arbitrary method invocation. There are two special cases: 
\begin{itemize}
	\item expressions like \texttt{!b} are translated into \texttt{b.unary\_!()}. This is true only for symbols \texttt{+},\texttt{-},\texttt{\~}, \texttt{!}.
	\item method ends with a colon (\texttt{:}), it binds to the right. This means that \texttt{1 \&: x} is translated into \texttt{x.\&:(1)}
\end{itemize}

There is a small inconsistency between normal methods and symbolic operators. The parser assigns higher priority to operators, so the code \texttt{m get k ! s} parses as \texttt{m.get(k.!(s))}, while \texttt{m get k tell s} will parse as \texttt{m.get(k).tell(s)}. This could be used to avoid some parentheses, but in general can probably cause confusion and bugs.

The ability to define custom operations allows us to implement the Operator Expressions pattern. We can emulate notation used by domain experts and create our own shorthands. The problem with using custom operators is that if we introduce new symbols that are unrelated to the domain we run the risk of creating completely unreadable code. When we're working in the domain of matrix manipulation, we can be reasonably confident as to what effect symbols like \texttt{+} or \texttt{*} have. But in a DSL used to create API endpoints, operators like \texttt{:++>>} or \texttt{<|*|>} are completely opaque, and worst of all, ungoogleable. Martin Odersky recently wrote: "But in retrospect I think maybe they did give a bad example for others to go overboard with symbolic operators." \autocite{Odersky:2016}


\section{Macros}

Macros in Scala are a type-safe way to facilitate compile-time metaprogramming. Unlike text-based substitution seen in languages like C, Scala macros transform the abstract syntax tree of parsed and correctly typed Scala code. The macro implementation is plain Scala code, but since the implementation needs to be available to the compiler, we need to compile it earlier.

We can use macros as a way to incorporate information that is available at compile time into code. This is best shown by \texttt{sqltyped}, a library which infers type information from SQL schema and query statements. Since it does this before compilation, we can have code that has the SQL snippet \texttt{select name, age from person where age > ?} which is automatically transformed into a function of type \texttt{Int => List[{ age: Int, name: String}]}.

The macro mechanism in Scala is extremely powerful. It can be used in the implementation of many notation patterns, especially since we can write code that better models the domain, and later transform it with macros to conform better to the capabilities of the host language.

Macro support in Scala is currently marked as experimental and is very actively being worked on. As such, between Scala versions 2.10 and 2.11 there have been several breaking changes and deprecations. This makes macros seem not to be a safe avenue of feature implementation.

\section{Object initialization expressions}

Scala supports using anonymous classes in programs. An anonymous class is a class that is defined and instantiated inline with code, often because it does not need to be reused. Anonymous classes can still use the normal inheritance mechanisms, so we can have on-off classes that are concise and powerful. In the context of DSLs, we can use this capability to implement the Block Scope and Supertype patterns. On listing~\ref{code:anonymous} we show how a DSL might use anonymous classes. The \texttt{Connection} and \texttt{Encryption} traits are part of the DSL implementation and encapsulate domain models relating to properties of connections. This usage gives us:
\begin{itemize}
	\item Type safety - we can restrict usage of unencrypted connections in by making sure that the connection implements the trait \texttt{Encryption}
	\item Supertype - the \texttt{connect} and \texttt{encrypt} methods can be used only within the scope of the new class body. The domain hierarchy is enforced by the language, which removes clutter and prevents mistakes.
	\item Block scope - connection properties may only be defined within the block used to define the new class instance. This guarantees that any and all information regarding a connection definition will be found in one place.
\end{itemize}

Unfortunately, usage of this pattern relies on a feature of Scala that cannot be abstracted from. The object must be constructed using the \texttt{new} operator and obey all rules of Scala scoping and object creation.

\begin{lstlisting}[caption=Anonymous classes, label=code:anonymous]
trait Connection {
  protected def connect = ...
  protected def on = ...
}

trait Encryption {
  protected def encrypt = ...
}

val conn = new Connection with Encryption {
  connect to "example.com"
  on port 223
  encrypt with TLS
}
\end{lstlisting}

\section{Other features}

\subsection{Type system}

The Scala type system provides many features that aid developers in implementing correct code. Local type inference is important to the notation aspect of DSLs since it allows us to omit type annotation in variable declarations, and possibly keep it out of the DSL entirely. Of course to help us build languages that are robust and extensible we can use all the other features of the Scala type system like variance annotations, type bounds, type members, structural typing, higher-kinded types, or existential types.

The issue with the type system is that with this large and continually growing amount of features it is easier to find strange corner cases that are at best counterintuitive and at worst broken. For example, Scala doesn't have full Hindleyâ€“Milner type inference. Instead, an expression is fully typed in the place that it appears in, and sometimes needs to be guided. This can lead to a situation like in listing~\ref{code:inference}, where the variable \texttt{b} was inferred to have type \texttt{X[Nothing]}. This makes it problematic to apply common expression extraction, because we could accidentaly remove code that guides the inference.

\begin{lstlisting}[caption=Local inference, label=code:inference]
class X[T] {
  def m(x: T) = this
}

val am = new X().m(1)

val b = new X()
val bm = b.m(1)

val c = new X[Int]
val cm = c(1)
\end{lstlisting}

Listing \ref{code:existentials} is a more convoluted, with its use of type bounds and existential types. However, it shows that sometimes the inference needs to be very explicitly guided to compile simple and evidently correct at all. It is especially confusing for code at line \ref{line:why}, where we have to annotate a value with a type that it already has.


\begin{lstlisting}[caption=Existential inference, label=code:existentials, escapechar=|, float, floatplacement=H]
trait InternalBound

class InternalImpl extends InternalBound

trait Container {
  type Internal <: InternalBound
}

class ContainerImpl extends Container {
  type Internal = InternalImpl
}

object Test {
  type ContainerWithInternal = (T, T#Internal) forSome { type T <: Container; }
  type CS = (A, B) forSome { type A <: Container; type B <: A#Internal }

  def construct[T <: Container](i: T, e: T#Internal): ContainerWithInternal = (i, e)

  //Type error
  //def constructCS1[A <: Container](a: A, b: A#Internal): CS = (a, b) |\label{line:why}|
  def constructCS2[A <: Container](a: A, b: A#Internal): CS = (a, b): (A, A#Internal)

  def main(args: Array[String]): Unit = {

    val container = new ContainerImpl
    val internal = new container.Internal()
    val internalWithCast: container.Internal = new container.Internal()

    //Type errors
    //val res1: ContainerWithInternal = (container, internal)
    //val res2: ContainerWithInternal = construct(container, internal)
    val res3: ContainerWithInternal = construct(container, (internal: container.Internal))
    val res4: ContainerWithInternal = construct[ContainerImpl](container, internal)

    val res5: ContainerWithInternal = (container, internalWithCast)
    val res6: ContainerWithInternal = construct(container, internalWithCast)
    val res7: ContainerWithInternal = construct[ContainerImpl](container, internalWithCast)
  }
}
\end{lstlisting}

\subsection{Named parameters \& default arguments}

The named parameters feature in Scala allows us to indicate which value to use as which parameter in a function. We can also define default values for arguments, so that we can skip them completely. With this we can implement the keyword parameters pattern, as seen in listing \ref{code:named}.

\begin{lstlisting}[caption=Named parameters \& default arguments, label=code:named]
def printName(firstName: String, middleName: String = "", lastName: String = "") = {
  println(s"\$firstName \$middleName \$lastName")
}
printName("John")
printName(firstName = "John", lastName = "Doe", middleName = "F")
\end{lstlisting}

\subsections{Objects as modules}

\section{Summary}
Each feature is barely enough rope to hang ourselves, but we can tie the ropes together.
