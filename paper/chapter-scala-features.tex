\chapter{Scala features}
The core philosophy of Scala is for it to be a `scalable language', one which can adapt to the needs of its users \autocite{Odersky:2004}.
The creators wanted it to be an equally good choice for both small, simple programs and for large components of complex systems.
To this end, Scala contains many different language features, some of which are explicitly in service of implementing DSLs.
In this chapter we explore how the various patterns used in DSL implementation are supported in Scala.

\section{Parsing}

Scala has good support for creating parsers.
There is a Scala standard parser combinator library \texttt{scala.util.parsing}, third-party parsing libraries like \texttt{FastParse}, and a parser generator utility \texttt{parboiled2} written in Scala.
Thanks to Java interop we can also use parsing libraries for Java.
When writing custom parsers, aspects of the language like pattern matching and first-class functions are extremely helpful in keeping the code concise and readable.
While this doesn't make the effort needed to create a parser inconsequential, it does make Scala an attractive choice for implementing external DSLs.

\section{Execution}

While the interpretation of a program in AST form  (usually) doesn't pose much problem, it is much harder to generate an executable binary file.
There exist Scala libraries that allow the generation of JVM classfiles such as \texttt{Cafebabe}, but as of writing we have not found a library that allows for the creation of any binary executable format.
This is problematic if we want to execute programs written in the DSL in an environment that does not support the JVM.

\section{Internal modeling}

\subsection{Implicits}

The implicits mechanism in Scala has two main components: implicit values/parameters, and implicit conversions.
Although these components have different uses and meaning, they usually serve a common goal: to hide away a detail of the implementation that is necessary, but doesn't have to be exposed to the user at all times.

\subsubsection{Implicit values/parameters}

A function can declare that some of its arguments are {\it implicit}.
These arguments can be omitted at the call site, and the compiler will perform an {\it implicit lookup}.
This action searches in a number of places for a value of the type declared in the argument list, and applies it if found.
Implicit values can also be retrieved using the built-in function \texttt{implicitly[T]}.
A common use is in functions that want to separate arguments that are logically part of the computation from arguments that represent some execution context.
For example, in a library that implements support for asynchronous computations we would have an \texttt{ExecutorService} that provides access to a configured thread pool.
Functions from this library would require an \texttt{ExecutorService} as an argument to executo work on other threads.
Marking the \texttt{ExecutorService} as implicit allows us to omit it from the function calls and unclutter our code, as shown in Listings \ref{code:without_implicit} and \ref{code:with_implicit}

\begin{lstlisting}[caption=Code without implicits, label=code:without_implicit]
def async[T](code: => T)(ex: ExecutorService) = ...
def scheduleOnce[T](code: => T, delay: Duration)(ex: ExecutorService) = ...

val ex: ExecutorService = ...
val k = async(expensiveOperation1())(ex)
val v = async(expensiveOperation2())(ex)
scheduleOnce(doThisAgain(), 1.hour)(ex)
\end{lstlisting}

\begin{lstlisting}[caption=Code with implicits, label=code:with_implicit]
def async[T](code: => T)(implicit ex: ExecutorService) = ...
def scheduleOnce[T](code: => T, delay: Duration)(implicit ex: ExecutorService) = ...

implicit val ex: ExecutorService = ...
val k = async(expensiveOperation1())
val v = async(expensiveOperation2())
scheduleOnce(doThisAgain(), 1.hour)
\end{lstlisting}

\subsubsection{Implicit conversions}
Unary functions can be marked as {\it implicit} to become implicit conversions.
This allows us to use expressions of type \texttt{A} as if they had type \texttt{B}, as long as there exists an implicit conversion of type \texttt{A => B} that can be found by the implicit lookup mechanism.
This includes method calls, so we can call methods of type \texttt{B} on values of type \texttt{A}.
Implicit conversions can be useful when we are using a library that requires a datatype that is different from what is used internally.
Listing \ref{code:conversions} shows an interface that uses byte arrays, but we use implicit conversions to transparently use String within our program.

\begin{lstlisting}[caption=Implicit conversions, label=code:conversions, float]
def put(key: Array[Byte], value: Array[Byte]) = ...
def get(key: Array[Byte]): Array[Byte] = ...

implicit def bytesToString(bytes: Array[Byte]): String = {
  new String(bytes)
}
implicit def stringToBytes(string: String): Array[Byte]= {
  string.getBytes
}

put("k1", "v1")
put("k2", "v2")
val result: String = get("k3")
\end{lstlisting}

Implicit parameters and implicit conversion help us in implementing the `clean method calls' pattern, since methods and parameters that aren't part of the domain but are necessary in the implementation of the language can be sometimes completely omitted.

\subsubsection{Implicit classes}
An implicit class is a shorthand definition of a class with a one-argument constructor alongside an implicit conversion from the argument to that class.
This simplifies the implementation of the `Enriched Class' pattern, which imitates adding methods to existing classes.
Listing \ref{code:implicit_classes} shows a simple extension of the Int class.
Now the method \texttt{toHexString} is available on any instance of \texttt{Int} as long as the implicit class can be located.

\begin{lstlisting}[caption=Implicit class, label=code:implicit_classes, float]
implicit class RichInt(val self: Int) {
  def toHexString: String = java.lang.Integer.toHexString(self)
}

val i: Int = 5
println(i.toHexString)
\end{lstlisting}

With implicit classes we can further remove non-domain symbols from the language by making implicit the creation of domain objects from objects in the host language.

\subsubsection{Context bounds}
Context bounds are a way to express more information at the level of the type system.
The expression \texttt{def f[T: Ordered](x: T) = \ldots} means that for a given type \texttt{T}, there exists an implementation of the trait \texttt{Ordered}, i.e. there exists a value of type \texttt{Ordered[T]}.
This is actually just syntactic sugar which compiles to \texttt{def f[T](x: T)(implicit ev: Ordered[T])}.
This mechanism is often used to emulate the behavior of Haskell type classes.
Listing \ref{code:context_bounds} presents the implementation of the Show type class in Scala, which us slightly more verbose than in Haskell.

\begin{lstlisting}[caption=Context bounds, label=code:context_bounds, float]
trait Show[T] {
  def show(t: T): String
}
def print[T: Show](t: T) = {
  val str = implicitly[Show[T]].show(t)
  println(str)
}

implicit val showableInt: Show[Int] = new Show[Int] {
  def show(i: Int): String = i.toString
}
implicit val showableFloat: Show[Float] = new Show[Float] {
  def show(f: Float): String = f.toString
}
print(1)
print(2f)
print("3") //will not compile since there is no implementation of Show[String]
\end{lstlisting}

There is a similar construct called the view bound.
The code \texttt{def f[T <\% B](x: T)} means that the type \texttt{T} can be viewed as as type \texttt{B}, and it desugars to \texttt{def f[T](x: T)(implicit ev: T => B)}.
However, this is currently deprecated and will be removed in future versions of Scala, as it can be easily reproduce using context bounds.

\subsubsection{Implicit lookup}

The implicit lookup algorithm checks the following locations\footnote{http://docs.scala-lang.org/tutorials/FAQ/finding-implicits.html}: 

\begin{enumerate}
	\item First look in current scope
	\begin{itemize}
		\item Implicits defined in current scope (\texttt{implicit val x = ...})
    \item Explicit imports (\texttt{import dsl.byte2String})
    \item Wildcard imports (\texttt{import dsl.\_})
	\end{itemize}
	\item Now look at associated types in
	\begin{itemize}
		\item Companion objects of a type
		\item Implicit scope of an argumentâ€™s type
		\item Implicit scope of type arguments
		\item Outer objects for nested types
	\end{itemize}
\end{enumerate}

The implicits found in group 1 take precedence over implicits found in group 2.
If multiple matching implicits are found, we choose the one with the most specific type (this requires another, slightly more technical computation).
Otherwise, if none are found or we cannot disambiguate the implicit, the compilation fails.

\subsubsection{Criticisms}

Criticizing implicits is a common thread in online discussions about Scala \autocite{Plush:2015, lakes:2009, Allan:2013, Hale:2011}.
While not actually broken, implicits are a powerful and complex feature that is very prone to abuse.

The Scala collections library is an interesting example of implicit parameter (ab)use.
Sometimes called the "Longest suicide note in history" \autocite{lakes:2009}, it uses implicit parameters and the \texttt{CanBuildFrom} type class to provide robust operations on collections.
Looking at the \texttt{map} method of \texttt{List[A]} which we expect to have the type signature \texttt{def map[B](f: A => B): List[B]}.
The actual signature is:
\begin{verbatim}
def map[B, That](f: A => B)
  (implicit bf: CanBuildFrom[Repr, B, That]): That
\end{verbatim}
Listing~\ref{code:bitset} (taken from a response to \autocite{lakes:2009}) shows that the implicit parameter in \texttt{map} is used to find the best possible return type for that method.
While this is a powerful result, the function signature can be confusing and signals that this is a leaky abstraction.
Scala maintainers agree with this, and in newer versions of Scala the documentation doesn't show the real type, but the one that we expected in the beginning.

\begin{lstlisting}[caption=Bitset example, label=code:bitset]
scala> val bits = BitSet(1, 2, 3)
bits: scala.collection.immutable.BitSet = BitSet(1, 2, 3)

scala> val shifted = bits map { _ + 1 }
shifted: scala.collection.immutable.BitSet = BitSet(2, 3, 4)

scala> val displayed = bits map { _.toString + "!" }
displayed: scala.collection.immutable.Set[java.lang.String] = Set(1!, 2!, 3!)
\end{lstlisting}

Leaky abstractions expose the main problem of implicits, which is the large amount of mental effort needed when reasoning about them.
When we encounter a problem or confusion with implicits, we cannot immediately say where a value came from.
We need to know the implicit lookup algorithm which, while not complex, is not intuitive.
Poorly designed implicit conversions can also hide errors.
The implicit lookup algorithm fires every time there is a type error in a program, and tries to find a conversion which will let it compile.
We now run a risk of accidentally compiling code that should have caused a type error because it just happened to find a fitting conversion.

\subsection{Method invocation}

Basic Scala method invocation is identical to Java method invocation.
However, there are various alternatives to that notation that Scala allows.

\begin{itemize}
	\item When invoking methods that don't take arguments, we can omit the empty parentheses (\texttt{list.size} instead of \texttt{list.size()}).
	\item When invoking methods that take one parameter, we can use the infix notation, i.e. omit the dot and parentheses ((\texttt{list append 1} instead of \texttt{list.append(1)}))
	\item We can chain infix method invocations.
\texttt{a m1 a1 m2 a2 m3} compiles as\\ \texttt{a.m1(a1).m2(a2).m3()}
	\item If we keep parentheses around methods with multiple arguments, we can omit all dots in an expression.
\texttt{a m1(a1, a2) m2 a2} will compile to \texttt{a.m1(a1, a2).m2(a2)}
\end{itemize}

These syntax options are crucial in enabling the Method Chaining and Clean Method Calls patterns.
However care must be taken to understand the rules of how expressions like these are parsed.
The following code listings show two expressions that look extremely similar.
However, the expression in the first listing compiles to \texttt{a.m(m).b}, whereas the other expression is actually two expressions: \texttt{a.m(); m.b()}.
In a well designed language this would usually cause a compilation error, but some DSLs might want to reuse the same name in different contexts, which could lead to both code snippets being valid.

\begin{minipage}[t]{0.4\textwidth}
\begin{lstlisting}[caption=One expression]
a m
m b
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}[t]{0.4\textwidth}
\begin{lstlisting}[caption=Two expressions]
a m

m b
\end{lstlisting}
\end{minipage}

\subsection{Operator overloading}

Scala allows us to define methods whose names contain symbols.
When combined with infix method invocation we get a notation that resembles operator overloading, but is in fact just arbitrary method invocation.
There are two special cases: 
\begin{itemize}
	\item expressions like \texttt{!b} are translated into \texttt{b.unary\_!()}.
This is true only for symbols \texttt{+},\texttt{-},\texttt{\~}, \texttt{!}.
	\item method ends with a colon (\texttt{:}), it binds to the right.
This means that \texttt{1 \&: x} is translated into \texttt{x.\&:(1)}
\end{itemize}

There is a small inconsistency between normal methods and symbolic operators.
The parser assigns higher priority to operators, so the code \texttt{m get k ! s} parses as \texttt{m.get(k.!(s))}, while \texttt{m get k tell s} will parse as \texttt{m.get(k).tell(s)}.
This could be used to avoid some parentheses, but in general can probably cause confusion and bugs.

The ability to define custom operations allows us to implement the Operator Expressions pattern.
We can emulate notation used by domain experts and create our own shorthands.
The problem with using custom operators is that if we introduce new symbols that are unrelated to the domain we run the risk of creating completely unreadable code.
When we're working in the domain of matrix manipulation, we can be reasonably confident as to what effect symbols like \texttt{+} or \texttt{*} have.
But in a DSL used to create API endpoints, operators like \texttt{:++>>} or \texttt{<|*|>} are completely opaque, and worst of all, ungoogleable.
Martin Odersky recently wrote: "But in retrospect I think maybe they did give a bad example for others to go overboard with symbolic operators" \autocite{Odersky:2016}.


\subsection{Macros}

Macros in Scala are a type-safe way to facilitate compile-time metaprogramming.
Unlike text-based substitution seen in languages like C, Scala macros transform the abstract syntax tree of parsed and correctly typed Scala code.
The macro implementation is plain Scala code, but since the implementation needs to be available to the compiler, we need to compile it earlier.

We can use macros as a way to incorporate information that is available at compile time into code.
This is best shown by \texttt{sqltyped}, a library which infers type information from SQL schema and query statements.
Since it does this before compilation, we can have code that has the SQL snippet \texttt{select name, age from person where age > ?} which is automatically transformed into a function of type \texttt{Int => List[\{ age: Int, name: String\}]}.

The macro mechanism in Scala is extremely powerful.
It can be used in the implementation of many notation patterns, especially since we can write code that better models the domain, and later transform it with macros to conform better to the capabilities of the host language.

Macro support in Scala is currently marked as experimental and is very actively being worked on.
As such, between Scala versions 2.10 and 2.11 there have been several breaking changes and deprecations.
Scala 2.12 will not add new features.
Instead, work will be focused on a net metaprogramming API, \texttt{scala.meta}.
This makes macros seem not to be a safe avenue of feature implementation.

\subsection{Object initialization expressions}

Scala supports using anonymous classes in programs.
An anonymous class is a class that is defined and instantiated inline with code, often because it does not need to be reused.
Anonymous classes can still use the normal inheritance mechanisms, so we can have one-off classes that are concise and powerful.
In the context of DSLs, we can use this capability to implement the Block Scope and Supertype patterns.
In Listing~\ref{code:anonymous} we show how a DSL might use anonymous classes.
The \texttt{Connection} and \texttt{Encryption} traits are part of the DSL implementation and encapsulate domain models relating to properties of connections.
This usage gives us:
\begin{itemize}
	\item Type safety -- we can restrict usage of unencrypted connections by making sure that the connection implements the trait \texttt{Encryption}
	\item Supertype -- the \texttt{connect} and \texttt{encrypt} methods can be used only within the scope of the new class body.
The domain hierarchy is enforced by the language, which removes clutter and prevents mistakes.
	\item Block scope -- connection properties may only be defined within the block used to define the new class instance.
This guarantees that any and all information regarding a connection definition will be found in one place.
\end{itemize}

Unfortunately, the usage of this pattern relies on a feature of Scala that cannot be abstracted from.
The object must be constructed using the \texttt{new} operator and obey all rules of Scala scoping and object creation.

\begin{lstlisting}[caption=Anonymous classes, label=code:anonymous]
trait Connection {
  protected def connect = ...
  protected def on = ...
}

trait Encryption {
  protected def encrypt = ...
}

val conn = new Connection with Encryption {
  connect to "example.com"
  on port 223
  encrypt with TLS
}
\end{lstlisting}

\section{Other features}

\subsection{Type system}

The Scala type system provides many features that aid developers in implementing correct code.
Local type inference is important to the notation aspect of DSLs since it allows us to omit type annotation in variable declarations, and possibly keep it out of the DSL entirely.
Of course to help us build languages that are robust and extensible we can use all the other features of the Scala type system like variance annotations, type bounds, type members, structural typing, higher-kinded types, or existential types.

The issue with the type system is that with this large and continually growing amount of features it is easier to find strange corner cases that are at best counterintuitive and at worst broken.
For example, Scala doesn't have full Hindleyâ€“Milner type inference.
Instead, an expression is fully typed in the place that it appears in, and sometimes needs to be guided.
This can lead to a situation like in Listing~\ref{code:inference}, where the variable \texttt{b} was inferred to have type \texttt{X[Nothing]}.
This makes it problematic to apply common expression extraction, because we could accidentally remove code that guides the inference.

\begin{lstlisting}[caption=Local inference, label=code:inference, float]
class X[T] {
  def m(x: T) = this
}

val am = new X().m(1)

val b = new X()
val bm = b.m(1) //Won't compile

val c = new X[Int]
val cm = c.m(1)
\end{lstlisting}

Using the more advanced features of the type system like existential types or type bounds can lead to situations where it is not obvious why our program does not work.
We can construct a program where the type checker has to be so explicitly guided that we have to annotate an expression with a type that it already has.
Listing \ref{code:existentials} shows some of these constructions.

\subsection{Named parameters and default arguments}

The named parameters feature in Scala allows us to indicate which value to use as which parameter in a function.
We can also define default values for arguments, so that we can skip them completely.
With this feature we can implement the keyword parameters pattern, as seen in listing \ref{code:named}.

\begin{lstlisting}[caption=Named parameters and default arguments, label=code:named]
def printName(
  firstName: String,
  middleName: String = "",
  lastName: String = "") = {
    println(List(firstName, middleName, lastName).mkString(" "))
}
printName("John")
printName(firstName = "John", lastName = "Doe", middleName = "F")
\end{lstlisting}

\subsection{Objects as modules}

In Scala, every named function must be a method of a class instance.
Normally, this would mean that every method call would either be called on a named class instance, or be made inside a class, where we have a default reference \texttt{this}.
However, Scala provides the ability to import into scope members of a class instance with the same notation used for importing class definitions.
Listing \ref{code:modules} shows how we can use this to encode an ML-style module system.
A system like this allows us to bring into scope definitions of values and functions without having to create objects or refer to them by name.

\begin{lstlisting}[caption=Modules, label=code:modules, float]
object module {
  def f = ...
  def g() = ...
}

import module._ //imports all members of object Module
f //Calls module.f()
\end{lstlisting}

\section{Summary}

We have presented several Scala features that we think are important components in the implementation of internal DSLs.
They are all accompanied by critical opinions and caveats.
While no one feature can be pointed to as broken, the accumulated cognitive load when interacting with several features at the same time can prove to be overwhelming.
This is compounded by the fact that there is no real concept of `idiomatic Scala' within the community, which leads to fragmentation in coding styles and opinions (from \cite{Hale:2011} "a best practice emerged: ignore the community entirely").
We conclude with two facts useful when designing DSLs: that Scala features should be used very carefully, and that language design is hard.
